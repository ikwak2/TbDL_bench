{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reported (reproduced, xgboost) results of of TabTransformer model based on\n",
    "Table 1 of original paper https://arxiv.org/abs/2012.06678.\n",
    "\n",
    "adult: 73.8 (88.86)\n",
    "bank-marketing: 93.4 (90.83, 81.00)\n",
    "dota2: 63.3 (52.44, 53.75)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_frame import stype\n",
    "from torch_frame.data import Dataset, DataLoader\n",
    "from torch_frame.datasets import AdultCensusIncome, BankMarketing, Dota2\n",
    "from torch_frame.nn import TabTransformer\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    FTTransformer,\n",
    "    LinearBucketEncoder,\n",
    "    LinearEncoder,\n",
    "    LinearPeriodicEncoder,\n",
    "    ResNet,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default='dota2',\n",
    "                    choices=[\"adult\", \"dota2\", \"bank-marketing\"])\n",
    "parser.add_argument('--channels', type=int, default=32)\n",
    "parser.add_argument('--num_heads', type=int, default=8)\n",
    "parser.add_argument('--num_layers', type=int, default=6)\n",
    "parser.add_argument('--encoder_pad_size', type=int, default=2)\n",
    "parser.add_argument('--attention_dropout', type=float, default=0.3)\n",
    "parser.add_argument('--ffn_dropout', type=float, default=0.3)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--epochs', type=int, default=50)\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--compile', action='store_true')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter에서 실행될 때는 sys.argv를 조정\n",
    "args = parser.parse_args([\n",
    "    '--channels', '256',\n",
    "    '--num_layers', '4',\n",
    "    '--batch_size', '256',  # 데이터를 256개씩 한번에 \n",
    "    '--lr', '0.0001',\n",
    "    '--epochs', '15',\n",
    "    '--seed', '0'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 ( => 이 부분만 조작)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- object => categorical\n",
    "- int / float => numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alzheimers_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74283 entries, 0 to 74282\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Country                               74283 non-null  object \n",
      " 1   Age                                   74283 non-null  int64  \n",
      " 2   Gender                                74283 non-null  object \n",
      " 3   Education Level                       74283 non-null  int64  \n",
      " 4   BMI                                   74283 non-null  float64\n",
      " 5   Physical Activity Level               74283 non-null  object \n",
      " 6   Smoking Status                        74283 non-null  object \n",
      " 7   Alcohol Consumption                   74283 non-null  object \n",
      " 8   Diabetes                              74283 non-null  object \n",
      " 9   Hypertension                          74283 non-null  object \n",
      " 10  Cholesterol Level                     74283 non-null  object \n",
      " 11  Family History of Alzheimer’s         74283 non-null  object \n",
      " 12  Cognitive Test Score                  74283 non-null  int64  \n",
      " 13  Depression Level                      74283 non-null  object \n",
      " 14  Sleep Quality                         74283 non-null  object \n",
      " 15  Dietary Habits                        74283 non-null  object \n",
      " 16  Air Pollution Exposure                74283 non-null  object \n",
      " 17  Employment Status                     74283 non-null  object \n",
      " 18  Marital Status                        74283 non-null  object \n",
      " 19  Genetic Risk Factor (APOE-ε4 allele)  74283 non-null  object \n",
      " 20  Social Engagement Level               74283 non-null  object \n",
      " 21  Income Level                          74283 non-null  object \n",
      " 22  Stress Levels                         74283 non-null  object \n",
      " 23  Urban vs Rural Living                 74283 non-null  object \n",
      " 24  Alzheimer’s Diagnosis                 74283 non-null  object \n",
      "dtypes: float64(1), int64(3), object(21)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"alzheimers_prediction_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Alzheimer’s Diagnosis\"].unique()    # 진단받았는지 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- object => categorical\n",
    "- int / float => numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Country\" : categorical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Gender\" : categorical,\n",
    "              \"Education Level\" : numerical,\n",
    "              \"BMI\" : numerical,\n",
    "              \"Physical Activity Level\" : categorical,\n",
    "              \"Smoking Status\" : categorical,\n",
    "              \"Alcohol Consumption\" : categorical,\n",
    "              \"Diabetes\" : categorical,\n",
    "              \"Hypertension\" : categorical,\n",
    "              \"Cholesterol Level\" : categorical,\n",
    "              \"Family History of Alzheimer’s\" : categorical,\n",
    "              \"Cognitive Test Score\" : numerical,\n",
    "              \"Depression Level\" : categorical,\n",
    "              \"Sleep Quality\" : categorical,\n",
    "              \"Dietary Habits\" : categorical,\n",
    "              \"Air Pollution Exposure\" : categorical,\n",
    "              \"Employment Status\" : categorical,\n",
    "              \"Marital Status\" : categorical,\n",
    "              \"Genetic Risk Factor (APOE-ε4 allele)\" : categorical,\n",
    "              \"Social Engagement Level\" : categorical,\n",
    "              \"Income Level\" : categorical,\n",
    "              \"Stress Levels\" : categorical,\n",
    "              \"Urban vs Rural Living\" : categorical,\n",
    "              \"Alzheimer’s Diagnosis\" : categorical\n",
    "              }\n",
    "\n",
    "dataset = Dataset(df = df, \n",
    "                  col_to_stype = col_to_stype, \n",
    "                  target_col = \"Alzheimer’s Diagnosis\")\n",
    "\n",
    "dataset.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드로 하니까 되네??? <br>\n",
    "DataFrame 형식이 아니라 이제 materialize가 됨. <br>\n",
    "나중에 더 자세히 알아보쟈 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,   => 분류 칼럼 unique 개수로 설정 \n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<stype.categorical: 'categorical'>: ['Air Pollution Exposure', 'Alcohol Consumption', 'Cholesterol Level', 'Country', 'Depression Level', 'Diabetes', 'Dietary Habits', 'Employment Status', 'Family History of Alzheimer’s', 'Gender', 'Genetic Risk Factor (APOE-ε4 allele)', 'Hypertension', 'Income Level', 'Marital Status', 'Physical Activity Level', 'Sleep Quality', 'Smoking Status', 'Social Engagement Level', 'Stress Levels', 'Urban vs Rural Living'], <stype.numerical: 'numerical'>: ['Age', 'BMI', 'Cognitive Test Score', 'Education Level']}\n"
     ]
    }
   ],
   "source": [
    "print(train_tensor_frame.col_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Disease Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Chest_Pain           70000 non-null  float64\n",
      " 1   Shortness_of_Breath  70000 non-null  float64\n",
      " 2   Fatigue              70000 non-null  float64\n",
      " 3   Palpitations         70000 non-null  float64\n",
      " 4   Dizziness            70000 non-null  float64\n",
      " 5   Swelling             70000 non-null  float64\n",
      " 6   Pain_Arms_Jaw_Back   70000 non-null  float64\n",
      " 7   Cold_Sweats_Nausea   70000 non-null  float64\n",
      " 8   High_BP              70000 non-null  float64\n",
      " 9   High_Cholesterol     70000 non-null  float64\n",
      " 10  Diabetes             70000 non-null  float64\n",
      " 11  Smoking              70000 non-null  float64\n",
      " 12  Obesity              70000 non-null  float64\n",
      " 13  Sedentary_Lifestyle  70000 non-null  float64\n",
      " 14  Family_History       70000 non-null  float64\n",
      " 15  Chronic_Stress       70000 non-null  float64\n",
      " 16  Gender               70000 non-null  float64\n",
      " 17  Age                  70000 non-null  float64\n",
      " 18  Heart_Risk           70000 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_disease_risk_dataset_earlymed.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Heart_Risk\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Heart_Risk\"] = df[\"Heart_Risk\"].astype(int)\n",
    "df[\"Heart_Risk\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Chest_Pain\" : numerical,\n",
    "              \"Shortness_of_Breath\" : numerical,\n",
    "              \"Fatigue\" : numerical,\n",
    "              \"Palpitations\" : numerical,\n",
    "              \"Dizziness\" : numerical,\n",
    "              \"Swelling\" : numerical,\n",
    "              \"Pain_Arms_Jaw_Back\" : numerical,\n",
    "              \"Cold_Sweats_Nausea\" : numerical,\n",
    "              \"High_BP\" : numerical,\n",
    "              \"High_Cholesterol\" : numerical,\n",
    "              \"Diabetes\" : numerical,\n",
    "              \"Smoking\" : numerical,\n",
    "              \"Obesity\" : numerical,\n",
    "              \"Sedentary_Lifestyle\" : numerical,\n",
    "              \"Family_History\" : numerical,\n",
    "              \"Chronic_Stress\" : numerical,\n",
    "              \"Gender\" : numerical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Heart_Risk\" : numerical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='Heart_Risk')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thyroid Cancer Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212691 entries, 0 to 212690\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Patient_ID           212691 non-null  int64  \n",
      " 1   Age                  212691 non-null  int64  \n",
      " 2   Gender               212691 non-null  object \n",
      " 3   Country              212691 non-null  object \n",
      " 4   Ethnicity            212691 non-null  object \n",
      " 5   Family_History       212691 non-null  object \n",
      " 6   Radiation_Exposure   212691 non-null  object \n",
      " 7   Iodine_Deficiency    212691 non-null  object \n",
      " 8   Smoking              212691 non-null  object \n",
      " 9   Obesity              212691 non-null  object \n",
      " 10  Diabetes             212691 non-null  object \n",
      " 11  TSH_Level            212691 non-null  float64\n",
      " 12  T3_Level             212691 non-null  float64\n",
      " 13  T4_Level             212691 non-null  float64\n",
      " 14  Nodule_Size          212691 non-null  float64\n",
      " 15  Thyroid_Cancer_Risk  212691 non-null  object \n",
      " 16  Diagnosis            212691 non-null  object \n",
      "dtypes: float64(4), int64(2), object(11)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"thyroid_cancer_risk_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Malignant'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Diagnosis\"].unique()    # 진단받았는지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={#\"Patient_ID\" : numerical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Gender\" : categorical,\n",
    "              \"Country\" : categorical,\n",
    "              \"Ethnicity\" : categorical,\n",
    "              \"Family_History\" : categorical,\n",
    "              \"Radiation_Exposure\" : categorical,\n",
    "              \"Iodine_Deficiency\" : categorical,\n",
    "              \"Smoking\" : categorical,\n",
    "              \"Obesity\" : categorical,\n",
    "              \"Diabetes\" : categorical,\n",
    "              \"TSH_Level\" : numerical,\n",
    "              \"T3_Level\" : numerical,\n",
    "              \"T4_Level\" : numerical,\n",
    "              \"Nodule_Size\" : categorical,\n",
    "              \"Thyroid_Cancer_Risk\" : categorical,\n",
    "              \"Diagnosis\" : categorical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='Diagnosis')\n",
    "\n",
    "dataset.materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast-cancer.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특이점 : 예측 칼럼 제외 모두 수치형 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"diagnosis\"].unique()    # 이걸 예측하는 것. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M : Malignant\n",
    "- B : Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"radius_mean\" : numerical,\n",
    "              \"texture_mean\" : numerical,\n",
    "              \"perimeter_mean\" : numerical,\n",
    "              \"area_mean\" :numerical,\n",
    "              \"smoothness_mean\" : numerical,\n",
    "              \"compactness_mean\" : numerical,\n",
    "              \"concavity_mean\" : numerical,\n",
    "              \"concave points_mean\" : numerical,\n",
    "              \"symmetry_mean\" : numerical,\n",
    "              \"fractal_dimension_mean\" : numerical,\n",
    "              \"radius_se\" : numerical,\n",
    "              \"texture_se\" : numerical,\n",
    "              \"perimeter_se\" : numerical,\n",
    "              \"area_se\" : numerical,\n",
    "              \"smoothness_se\" : numerical,\n",
    "              \"compactness_se\" : numerical,\n",
    "              \"concavity_se\" : numerical,\n",
    "              \"concave points_se\" : numerical,\n",
    "              \"symmetry_se\" : numerical,\n",
    "              \"fractal_dimension_se\" : numerical,\n",
    "              \"radius_worst\" : numerical,\n",
    "              \"texture_worst\" : numerical,\n",
    "              \"perimeter_worst\" : numerical,\n",
    "              \"area_worst\" : numerical,\n",
    "              \"smoothness_worst\" : numerical,\n",
    "              \"compactness_worst\" : numerical,\n",
    "              \"concavity_worst\" : numerical,\n",
    "              \"concave points_worst\" : numerical,\n",
    "              \"symmetry_worst\" : numerical,\n",
    "              \"fractal_dimension_worst\" : numerical,\n",
    "              \"diagnosis\" : categorical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='diagnosis')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HeartDisease\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Age\" : numerical,\n",
    "              \"Sex\" : categorical,\n",
    "              \"ChestPainType\" : categorical,\n",
    "              \"RestingBP\" : numerical,\n",
    "              \"Cholesterol\" : numerical,\n",
    "              \"FastingBS\" : numerical,\n",
    "              \"RestingECG\" : categorical,\n",
    "              \"MaxHR\" : numerical,\n",
    "              \"ExerciseAngina\" : categorical,\n",
    "              \"Oldpeak\" : numerical,\n",
    "              \"ST_Slope\" : categorical,\n",
    "              \"HeartDisease\" : numerical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='HeartDisease')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'numerical_encoder_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_tensor_frame, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m      8\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_tensor_frame, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical_encoder_type\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     11\u001b[0m     numerical_encoder \u001b[38;5;241m=\u001b[39m LinearEncoder()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnumerical_encoder_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinearbucket\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'numerical_encoder_type'"
     ]
    }
   ],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model and optimizer\n",
    "model = TabTransformer(\n",
    "    channels=args.channels,\n",
    "    out_channels= 2,        # stype 문제로 수동으로 설정 \n",
    "    num_layers=args.num_layers,\n",
    "    num_heads=args.num_heads,\n",
    "    encoder_pad_size=args.encoder_pad_size,\n",
    "    attn_dropout=args.attention_dropout,\n",
    "    ffn_dropout=args.ffn_dropout,\n",
    "    col_stats=dataset.col_stats,\n",
    "    col_names_dict=train_tensor_frame.col_names_dict,\n",
    ").to(device)\n",
    "model = torch.compile(model, dynamic=True) if args.compile else model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    for tf in tqdm(train_loader, desc=f'Epoch: {epoch}'):\n",
    "        tf = tf.to(device)\n",
    "        pred = model.forward(tf)\n",
    "        loss = F.cross_entropy(pred, tf.y.long())   # expected scalar type Long but found Float 때문에 tf.y => tf.y.long()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_accum += float(loss) * len(tf.y)\n",
    "        total_count += len(tf.y)\n",
    "        optimizer.step()\n",
    "    return loss_accum / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accum = total_count = 0\n",
    "\n",
    "    for tf in loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        if is_classification:\n",
    "            pred_class = pred.argmax(dim=-1)\n",
    "            accum += float((tf.y == pred_class).sum())\n",
    "        else:\n",
    "            accum += float(\n",
    "                F.mse_loss(pred.view(-1), tf.y.view(-1), reduction='sum'))\n",
    "        total_count += len(tf.y)\n",
    "\n",
    "    if is_classification:\n",
    "        accuracy = accum / total_count\n",
    "        return accuracy\n",
    "    else:\n",
    "        rmse = (accum / total_count)**0.5\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 3/3 [00:01<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7480, Train ACC: 0.8621, Val ACC: 0.8696, Test ACC: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 3/3 [00:00<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5878, Train ACC: 0.8784, Val ACC: 0.8478, Test ACC: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 3/3 [00:00<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4707, Train ACC: 0.8693, Val ACC: 0.8370, Test ACC: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 3/3 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4606, Train ACC: 0.8639, Val ACC: 0.8478, Test ACC: 0.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 3/3 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4564, Train ACC: 0.8621, Val ACC: 0.8261, Test ACC: 0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 3/3 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4753, Train ACC: 0.8530, Val ACC: 0.8152, Test ACC: 0.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 3/3 [00:00<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4167, Train ACC: 0.8566, Val ACC: 0.8043, Test ACC: 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 3/3 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4388, Train ACC: 0.8639, Val ACC: 0.8043, Test ACC: 0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 3/3 [00:00<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4321, Train ACC: 0.8675, Val ACC: 0.7935, Test ACC: 0.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 3/3 [00:00<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4582, Train ACC: 0.8621, Val ACC: 0.7935, Test ACC: 0.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 3/3 [00:00<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4632, Train ACC: 0.8603, Val ACC: 0.7935, Test ACC: 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 3/3 [00:00<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4446, Train ACC: 0.8657, Val ACC: 0.8152, Test ACC: 0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13: 100%|██████████| 3/3 [00:00<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4226, Train ACC: 0.8639, Val ACC: 0.8261, Test ACC: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 3/3 [00:00<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3499, Train ACC: 0.8730, Val ACC: 0.8478, Test ACC: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 3/3 [00:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3619, Train ACC: 0.8748, Val ACC: 0.8478, Test ACC: 0.7564\n",
      "Best Val ACC: 0.8696, Best Test ACC: 0.7782\n"
     ]
    }
   ],
   "source": [
    "metric = 'ACC'\n",
    "best_val_metric = 0\n",
    "best_test_metric = 0\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_metric = test(train_loader)\n",
    "    val_metric = test(val_loader)\n",
    "    test_metric = test(test_loader)\n",
    "\n",
    "    if val_metric > best_val_metric:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train {metric}: {train_metric:.4f}, '\n",
    "          f'Val {metric}: {val_metric:.4f}, Test {metric}: {test_metric:.4f}')\n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(f'Best Val {metric}: {best_val_metric:.4f}, '\n",
    "      f'Best Test {metric}: {best_test_metric:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
