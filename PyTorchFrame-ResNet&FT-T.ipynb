{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pyg-team/pytorch-frame/blob/master/benchmark/data_frame_benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\cleo7\\\\OneDrive\\\\바탕 화면\\\\LAB\\\\PyTorch_Frame\\\\pytorch-frame-0.2.4'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleo7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "from typing import Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, Module, MSELoss\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchmetrics import AUROC, Accuracy, MeanSquaredError\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_frame import stype\n",
    "from torch_frame.data import Dataset, DataLoader\n",
    "from torch_frame.datasets import DataFrameBenchmark\n",
    "from torch_frame.gbdt import CatBoost, LightGBM, XGBoost\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    FTTransformer,\n",
    "    LinearBucketEncoder,\n",
    "    LinearEncoder,\n",
    "    LinearPeriodicEncoder,\n",
    "    ResNet,\n",
    ")\n",
    "from torch_frame.nn.models import (\n",
    "    MLP,\n",
    "    ExcelFormer,\n",
    "    FTTransformer,\n",
    "    ResNet,\n",
    "    TabNet,\n",
    "    TabTransformer,\n",
    "    Trompt,\n",
    ")\n",
    "from torch_frame.typing import TaskType\n",
    "\n",
    "# Use GPU for faster training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--compile'], dest='compile', nargs=0, const=True, default=False, type=None, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default='adult')\n",
    "parser.add_argument('--numerical_encoder_type', type=str, default='linear',\n",
    "                    choices=['linear', 'linearbucket', 'linearperiodic'])\n",
    "parser.add_argument('--model_type', type=str, default='fttransformer',\n",
    "                    choices=['fttransformer', 'resnet'])\n",
    "parser.add_argument('--channels', type=int, default=256)\n",
    "parser.add_argument('--num_layers', type=int, default=4)\n",
    "parser.add_argument('--batch_size', type=int, default=512)\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--epochs', type=int, default=100)\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--compile', action='store_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class TextToEmbedding:\n",
    "    def __init__(self, model: str, device: torch.device):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = AutoModel.from_pretrained(model).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, sentences: list[str]) -> Tensor:\n",
    "        inputs = self.tokenizer(\n",
    "            sentences,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        for key in inputs:\n",
    "            if isinstance(inputs[key], Tensor):\n",
    "                inputs[key] = inputs[key].to(self.device)\n",
    "        out = self.model(**inputs)\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        return out.last_hidden_state[:, 0, :].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter에서 실행될 때는 sys.argv를 조정\n",
    "args = parser.parse_args([\n",
    "    #'--dataset', 'adult',\n",
    "    '--numerical_encoder_type', 'linear',\n",
    "    '--model_type', 'resnet',       # fttransformer : FT-T / resnet : ResNet\n",
    "    '--channels', '256',\n",
    "    '--num_layers', '4',\n",
    "    '--batch_size', '256',  # 데이터를 256개씩 한번에 \n",
    "    '--lr', '0.0001',\n",
    "    '--epochs', '15',\n",
    "    '--seed', '0'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 ( => 이 부분만 조작)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- object => categorical\n",
    "- int / float => numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alzheimers_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74283 entries, 0 to 74282\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Country                               74283 non-null  object \n",
      " 1   Age                                   74283 non-null  int64  \n",
      " 2   Gender                                74283 non-null  object \n",
      " 3   Education Level                       74283 non-null  int64  \n",
      " 4   BMI                                   74283 non-null  float64\n",
      " 5   Physical Activity Level               74283 non-null  object \n",
      " 6   Smoking Status                        74283 non-null  object \n",
      " 7   Alcohol Consumption                   74283 non-null  object \n",
      " 8   Diabetes                              74283 non-null  object \n",
      " 9   Hypertension                          74283 non-null  object \n",
      " 10  Cholesterol Level                     74283 non-null  object \n",
      " 11  Family History of Alzheimer’s         74283 non-null  object \n",
      " 12  Cognitive Test Score                  74283 non-null  int64  \n",
      " 13  Depression Level                      74283 non-null  object \n",
      " 14  Sleep Quality                         74283 non-null  object \n",
      " 15  Dietary Habits                        74283 non-null  object \n",
      " 16  Air Pollution Exposure                74283 non-null  object \n",
      " 17  Employment Status                     74283 non-null  object \n",
      " 18  Marital Status                        74283 non-null  object \n",
      " 19  Genetic Risk Factor (APOE-ε4 allele)  74283 non-null  object \n",
      " 20  Social Engagement Level               74283 non-null  object \n",
      " 21  Income Level                          74283 non-null  object \n",
      " 22  Stress Levels                         74283 non-null  object \n",
      " 23  Urban vs Rural Living                 74283 non-null  object \n",
      " 24  Alzheimer’s Diagnosis                 74283 non-null  object \n",
      "dtypes: float64(1), int64(3), object(21)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"alzheimers_prediction_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Alzheimer’s Diagnosis\"].unique()    # 진단받았는지 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- object => categorical\n",
    "- int / float => numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "text_encoder = TextToEmbedding(model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                                device=device)\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Country\" : categorical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Gender\" : categorical,\n",
    "              \"Education Level\" : numerical,\n",
    "              \"BMI\" : numerical,\n",
    "              \"Physical Activity Level\" : categorical,\n",
    "              \"Smoking Status\" : categorical,\n",
    "              \"Alcohol Consumption\" : categorical,\n",
    "              \"Diabetes\" : categorical,\n",
    "              \"Hypertension\" : categorical,\n",
    "              \"Cholesterol Level\" : categorical,\n",
    "              \"Family History of Alzheimer’s\" : categorical,\n",
    "              \"Cognitive Test Score\" : numerical,\n",
    "              \"Depression Level\" : categorical,\n",
    "              \"Sleep Quality\" : categorical,\n",
    "              \"Dietary Habits\" : categorical,\n",
    "              \"Air Pollution Exposure\" : categorical,\n",
    "              \"Employment Status\" : categorical,\n",
    "              \"Marital Status\" : categorical,\n",
    "              \"Genetic Risk Factor (APOE-ε4 allele)\" : categorical,\n",
    "              \"Social Engagement Level\" : categorical,\n",
    "              \"Income Level\" : categorical,\n",
    "              \"Stress Levels\" : categorical,\n",
    "              \"Urban vs Rural Living\" : categorical,\n",
    "              \"Alzheimer’s Diagnosis\" : categorical\n",
    "              }\n",
    "\n",
    "dataset = Dataset(df = df, \n",
    "                  col_to_stype = col_to_stype, \n",
    "                  target_col = \"Alzheimer’s Diagnosis\",\n",
    "                  col_to_text_embedder_cfg = TextEmbedderConfig(text_embedder=text_encoder, batch_size=32))\n",
    "\n",
    "dataset.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드로 하니까 되네??? <br>\n",
    "DataFrame 형식이 아니라 이제 materialize가 됨. <br>\n",
    "나중에 더 자세히 알아보쟈 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,   => 분류 칼럼 unique 개수로 설정 \n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<stype.categorical: 'categorical'>: ['Air Pollution Exposure', 'Alcohol Consumption', 'Cholesterol Level', 'Country', 'Depression Level', 'Diabetes', 'Dietary Habits', 'Employment Status', 'Family History of Alzheimer’s', 'Gender', 'Genetic Risk Factor (APOE-ε4 allele)', 'Hypertension', 'Income Level', 'Marital Status', 'Physical Activity Level', 'Sleep Quality', 'Smoking Status', 'Social Engagement Level', 'Stress Levels', 'Urban vs Rural Living'], <stype.numerical: 'numerical'>: ['Age', 'BMI', 'Cognitive Test Score', 'Education Level']}\n"
     ]
    }
   ],
   "source": [
    "print(train_tensor_frame.col_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Disease Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Chest_Pain           70000 non-null  float64\n",
      " 1   Shortness_of_Breath  70000 non-null  float64\n",
      " 2   Fatigue              70000 non-null  float64\n",
      " 3   Palpitations         70000 non-null  float64\n",
      " 4   Dizziness            70000 non-null  float64\n",
      " 5   Swelling             70000 non-null  float64\n",
      " 6   Pain_Arms_Jaw_Back   70000 non-null  float64\n",
      " 7   Cold_Sweats_Nausea   70000 non-null  float64\n",
      " 8   High_BP              70000 non-null  float64\n",
      " 9   High_Cholesterol     70000 non-null  float64\n",
      " 10  Diabetes             70000 non-null  float64\n",
      " 11  Smoking              70000 non-null  float64\n",
      " 12  Obesity              70000 non-null  float64\n",
      " 13  Sedentary_Lifestyle  70000 non-null  float64\n",
      " 14  Family_History       70000 non-null  float64\n",
      " 15  Chronic_Stress       70000 non-null  float64\n",
      " 16  Gender               70000 non-null  float64\n",
      " 17  Age                  70000 non-null  float64\n",
      " 18  Heart_Risk           70000 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_disease_risk_dataset_earlymed.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Heart_Risk\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Heart_Risk\"] = df[\"Heart_Risk\"].astype(int)\n",
    "df[\"Heart_Risk\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "text_encoder = TextToEmbedding(model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                                device=device)\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Chest_Pain\" : numerical,\n",
    "              \"Shortness_of_Breath\" : numerical,\n",
    "              \"Fatigue\" : numerical,\n",
    "              \"Palpitations\" : numerical,\n",
    "              \"Dizziness\" : numerical,\n",
    "              \"Swelling\" : numerical,\n",
    "              \"Pain_Arms_Jaw_Back\" : numerical,\n",
    "              \"Cold_Sweats_Nausea\" : numerical,\n",
    "              \"High_BP\" : numerical,\n",
    "              \"High_Cholesterol\" : numerical,\n",
    "              \"Diabetes\" : numerical,\n",
    "              \"Smoking\" : numerical,\n",
    "              \"Obesity\" : numerical,\n",
    "              \"Sedentary_Lifestyle\" : numerical,\n",
    "              \"Family_History\" : numerical,\n",
    "              \"Chronic_Stress\" : numerical,\n",
    "              \"Gender\" : numerical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Heart_Risk\" : numerical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='Heart_Risk',\n",
    "                  col_to_text_embedder_cfg=TextEmbedderConfig(text_embedder=text_encoder, batch_size=32))\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thyroid Cancer Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212691 entries, 0 to 212690\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Patient_ID           212691 non-null  int64  \n",
      " 1   Age                  212691 non-null  int64  \n",
      " 2   Gender               212691 non-null  object \n",
      " 3   Country              212691 non-null  object \n",
      " 4   Ethnicity            212691 non-null  object \n",
      " 5   Family_History       212691 non-null  object \n",
      " 6   Radiation_Exposure   212691 non-null  object \n",
      " 7   Iodine_Deficiency    212691 non-null  object \n",
      " 8   Smoking              212691 non-null  object \n",
      " 9   Obesity              212691 non-null  object \n",
      " 10  Diabetes             212691 non-null  object \n",
      " 11  TSH_Level            212691 non-null  float64\n",
      " 12  T3_Level             212691 non-null  float64\n",
      " 13  T4_Level             212691 non-null  float64\n",
      " 14  Nodule_Size          212691 non-null  float64\n",
      " 15  Thyroid_Cancer_Risk  212691 non-null  object \n",
      " 16  Diagnosis            212691 non-null  object \n",
      "dtypes: float64(4), int64(2), object(11)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"thyroid_cancer_risk_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Diagnosis\"].unique()    # 진단받았는지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "text_encoder = TextToEmbedding(model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                                device=device)\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={#\"Patient_ID\" : numerical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Gender\" : categorical,\n",
    "              \"Country\" : categorical,\n",
    "              \"Ethnicity\" : categorical,\n",
    "              \"Family_History\" : categorical,\n",
    "              \"Radiation_Exposure\" : categorical,\n",
    "              \"Iodine_Deficiency\" : categorical,\n",
    "              \"Smoking\" : categorical,\n",
    "              \"Obesity\" : categorical,\n",
    "              \"Diabetes\" : categorical,\n",
    "              \"TSH_Level\" : numerical,\n",
    "              \"T3_Level\" : numerical,\n",
    "              \"T4_Level\" : numerical,\n",
    "              \"Nodule_Size\" : categorical,\n",
    "              \"Thyroid_Cancer_Risk\" : categorical,\n",
    "              \"Diagnosis\" : categorical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='Diagnosis',\n",
    "                  col_to_text_embedder_cfg=TextEmbedderConfig(text_embedder=text_encoder, batch_size=32))\n",
    "\n",
    "dataset.materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast-cancer.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특이점 : 예측 칼럼 제외 모두 수치형 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"diagnosis\"].unique()    # 이걸 예측하는 것. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M : Malignant\n",
    "- B : Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"radius_mean\" : numerical,\n",
    "              \"texture_mean\" : numerical,\n",
    "              \"perimeter_mean\" : numerical,\n",
    "              \"area_mean\" :numerical,\n",
    "              \"smoothness_mean\" : numerical,\n",
    "              \"compactness_mean\" : numerical,\n",
    "              \"concavity_mean\" : numerical,\n",
    "              \"concave points_mean\" : numerical,\n",
    "              \"symmetry_mean\" : numerical,\n",
    "              \"fractal_dimension_mean\" : numerical,\n",
    "              \"radius_se\" : numerical,\n",
    "              \"texture_se\" : numerical,\n",
    "              \"perimeter_se\" : numerical,\n",
    "              \"area_se\" : numerical,\n",
    "              \"smoothness_se\" : numerical,\n",
    "              \"compactness_se\" : numerical,\n",
    "              \"concavity_se\" : numerical,\n",
    "              \"concave points_se\" : numerical,\n",
    "              \"symmetry_se\" : numerical,\n",
    "              \"fractal_dimension_se\" : numerical,\n",
    "              \"radius_worst\" : numerical,\n",
    "              \"texture_worst\" : numerical,\n",
    "              \"perimeter_worst\" : numerical,\n",
    "              \"area_worst\" : numerical,\n",
    "              \"smoothness_worst\" : numerical,\n",
    "              \"compactness_worst\" : numerical,\n",
    "              \"concavity_worst\" : numerical,\n",
    "              \"concave points_worst\" : numerical,\n",
    "              \"symmetry_worst\" : numerical,\n",
    "              \"fractal_dimension_worst\" : numerical,\n",
    "              \"diagnosis\" : categorical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='diagnosis')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HeartDisease\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Age\" : numerical,\n",
    "              \"Sex\" : categorical,\n",
    "              \"ChestPainType\" : categorical,\n",
    "              \"RestingBP\" : numerical,\n",
    "              \"Cholesterol\" : numerical,\n",
    "              \"FastingBS\" : numerical,\n",
    "              \"RestingECG\" : categorical,\n",
    "              \"MaxHR\" : numerical,\n",
    "              \"ExerciseAngina\" : categorical,\n",
    "              \"Oldpeak\" : numerical,\n",
    "              \"ST_Slope\" : categorical,\n",
    "              \"HeartDisease\" : numerical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='HeartDisease')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)\n",
    "\n",
    "if args.numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif args.numerical_encoder_type == 'linearbucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif args.numerical_encoder_type == 'linearperiodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f'Unsupported encoder type: {args.numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    #output_channels = dataset.num_classes    ->   contains StatType.COUNT을 포함하지 않아서 오류(?)\n",
    "    output_channels = 2 # 그냥 수동으로 설정.,,,,\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type == 'fttransformer':\n",
    "    model = FTTransformer(\n",
    "        channels=args.channels,\n",
    "        out_channels=output_channels,\n",
    "        num_layers=args.num_layers,\n",
    "        col_stats=dataset.col_stats,    # TensorFrame이 col_stats를 안받아서 transor frame으로 바꾸기 전으로 받아와야 함 \n",
    "        col_names_dict=train_tensor_frame.col_names_dict,\n",
    "        stype_encoder_dict=stype_encoder_dict,\n",
    "    ).to(device)\n",
    "\n",
    "elif args.model_type == 'resnet':\n",
    "    model = ResNet(\n",
    "        channels=args.channels,\n",
    "        out_channels=output_channels,\n",
    "        num_layers=args.num_layers,\n",
    "        col_stats=dataset.col_stats,\n",
    "        col_names_dict=train_tensor_frame.col_names_dict,\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise ValueError(f'Unsupported model type: {args.model_type}')\n",
    "\n",
    "model = torch.compile(model, dynamic=True) if args.compile else model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    for tf in tqdm(train_loader, desc=f'Epoch: {epoch}'):\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        if is_classification:\n",
    "            loss = F.cross_entropy(pred, tf.y.long())\n",
    "        else:\n",
    "            loss = F.mse_loss(pred.view(-1), tf.y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_accum += float(loss) * len(tf.y)\n",
    "        total_count += len(tf.y)\n",
    "        optimizer.step()\n",
    "    return loss_accum / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch에서 cross_entropy 함수는 타겟 레이블(target)이 torch.LongTensor(정수형)이어야 함. 따라서 tf.y를 long() 타입으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accum = total_count = 0\n",
    "\n",
    "    for tf in loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        if is_classification:\n",
    "            pred_class = pred.argmax(dim=-1)\n",
    "            accum += float((tf.y == pred_class).sum())\n",
    "        else:\n",
    "            accum += float(\n",
    "                F.mse_loss(pred.view(-1), tf.y.view(-1), reduction='sum'))\n",
    "        total_count += len(tf.y)\n",
    "\n",
    "    if is_classification:\n",
    "        accuracy = accum / total_count\n",
    "        return accuracy\n",
    "    else:\n",
    "        rmse = (accum / total_count)**0.5\n",
    "        return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 3/3 [00:00<00:00, 37.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6165, Train Acc: 0.8893, Val Acc: 0.8370, Test Acc: 0.7855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 3/3 [00:00<00:00, 42.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3648, Train Acc: 0.8893, Val Acc: 0.8478, Test Acc: 0.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 3/3 [00:00<00:00, 41.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3198, Train Acc: 0.8911, Val Acc: 0.8152, Test Acc: 0.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 3/3 [00:00<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2949, Train Acc: 0.8929, Val Acc: 0.8152, Test Acc: 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 3/3 [00:00<00:00, 46.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2881, Train Acc: 0.8911, Val Acc: 0.8370, Test Acc: 0.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 3/3 [00:00<00:00, 47.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2858, Train Acc: 0.8911, Val Acc: 0.8478, Test Acc: 0.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 3/3 [00:00<00:00, 45.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2831, Train Acc: 0.8929, Val Acc: 0.8370, Test Acc: 0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 3/3 [00:00<00:00, 41.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2855, Train Acc: 0.9056, Val Acc: 0.8370, Test Acc: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9: 100%|██████████| 3/3 [00:00<00:00, 37.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2784, Train Acc: 0.8966, Val Acc: 0.8370, Test Acc: 0.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 3/3 [00:00<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2768, Train Acc: 0.8947, Val Acc: 0.8370, Test Acc: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 3/3 [00:00<00:00, 48.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2650, Train Acc: 0.8947, Val Acc: 0.8261, Test Acc: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 3/3 [00:00<00:00, 35.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2742, Train Acc: 0.8966, Val Acc: 0.8261, Test Acc: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13: 100%|██████████| 3/3 [00:00<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2653, Train Acc: 0.9093, Val Acc: 0.8261, Test Acc: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 3/3 [00:00<00:00, 44.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2722, Train Acc: 0.9093, Val Acc: 0.8370, Test Acc: 0.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 3/3 [00:00<00:00, 37.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552, Train Acc: 0.8929, Val Acc: 0.8478, Test Acc: 0.7527\n",
      "Best Val Acc: 0.8478, Best Test Acc: 0.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련 및 테스트\n",
    "\n",
    "if is_classification:\n",
    "    metric = 'Acc'\n",
    "    best_val_metric = 0\n",
    "    best_test_metric = 0\n",
    "else:\n",
    "    metric = 'RMSE'\n",
    "    best_val_metric = float('inf')\n",
    "    best_test_metric = float('inf')\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_metric = test(train_loader)\n",
    "    val_metric = test(val_loader)\n",
    "    test_metric = test(test_loader)\n",
    "\n",
    "    if is_classification and val_metric > best_val_metric:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "    elif not is_classification and val_metric < best_val_metric:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train {metric}: {train_metric:.4f}, '\n",
    "          f'Val {metric}: {val_metric:.4f}, Test {metric}: {test_metric:.4f}')\n",
    "\n",
    "print(f'Best Val {metric}: {best_val_metric:.4f}, '\n",
    "      f'Best Test {metric}: {best_test_metric:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
