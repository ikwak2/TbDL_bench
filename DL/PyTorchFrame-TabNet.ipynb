{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reported (reproduced) results of of TabNet model in the original paper\n",
    "https://arxiv.org/abs/1908.07442.\n",
    "\n",
    "Forest Cover Type: 96.99 (96.53)\n",
    "KDD Census Income: 95.5 (95.41)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_frame import stype\n",
    "from torch_frame.data import Dataset, DataLoader\n",
    "from torch_frame.datasets import ForestCoverType, KDDCensusIncome\n",
    "from torch_frame.nn import TabNet\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    FTTransformer,\n",
    "    LinearBucketEncoder,\n",
    "    LinearEncoder,\n",
    "    LinearPeriodicEncoder,\n",
    "    ResNet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--compile'], dest='compile', nargs=0, const=True, default=False, type=None, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default=\"ForestCoverType\",\n",
    "                    choices=[\"ForestCoverType\", \"KDDCensusIncome\"])\n",
    "parser.add_argument('--channels', type=int, default=128)\n",
    "parser.add_argument('--gamma', type=int, default=1.2)\n",
    "parser.add_argument('--num_layers', type=int, default=6)\n",
    "parser.add_argument('--batch_size', type=int, default=4096)\n",
    "parser.add_argument('--lr', type=float, default=0.005)\n",
    "parser.add_argument('--epochs', type=int, default=50)\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--compile', action='store_true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 파라미터 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\n",
    "    \"--channels\", \"256\",\n",
    "    \"--num_layers\", \"4\",\n",
    "    \"--batch_size\", \"256\",\n",
    "    \"--lr\", \"0.0001\",\n",
    "    \"--epochs\", \"15\"\n",
    "])\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 ( => 이 부분만 조작)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- object => categorical\n",
    "- int / float => numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alzheimers_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74283 entries, 0 to 74282\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Country                               74283 non-null  object \n",
      " 1   Age                                   74283 non-null  int64  \n",
      " 2   Gender                                74283 non-null  object \n",
      " 3   Education Level                       74283 non-null  int64  \n",
      " 4   BMI                                   74283 non-null  float64\n",
      " 5   Physical Activity Level               74283 non-null  object \n",
      " 6   Smoking Status                        74283 non-null  object \n",
      " 7   Alcohol Consumption                   74283 non-null  object \n",
      " 8   Diabetes                              74283 non-null  object \n",
      " 9   Hypertension                          74283 non-null  object \n",
      " 10  Cholesterol Level                     74283 non-null  object \n",
      " 11  Family History of Alzheimer’s         74283 non-null  object \n",
      " 12  Cognitive Test Score                  74283 non-null  int64  \n",
      " 13  Depression Level                      74283 non-null  object \n",
      " 14  Sleep Quality                         74283 non-null  object \n",
      " 15  Dietary Habits                        74283 non-null  object \n",
      " 16  Air Pollution Exposure                74283 non-null  object \n",
      " 17  Employment Status                     74283 non-null  object \n",
      " 18  Marital Status                        74283 non-null  object \n",
      " 19  Genetic Risk Factor (APOE-ε4 allele)  74283 non-null  object \n",
      " 20  Social Engagement Level               74283 non-null  object \n",
      " 21  Income Level                          74283 non-null  object \n",
      " 22  Stress Levels                         74283 non-null  object \n",
      " 23  Urban vs Rural Living                 74283 non-null  object \n",
      " 24  Alzheimer’s Diagnosis                 74283 non-null  object \n",
      "dtypes: float64(1), int64(3), object(21)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"alzheimers_prediction_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Alzheimer’s Diagnosis\"].unique()    # 진단받았는지 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- object => categorical\n",
    "- int / float => numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Country\" : categorical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Gender\" : categorical,\n",
    "              \"Education Level\" : numerical,\n",
    "              \"BMI\" : numerical,\n",
    "              \"Physical Activity Level\" : categorical,\n",
    "              \"Smoking Status\" : categorical,\n",
    "              \"Alcohol Consumption\" : categorical,\n",
    "              \"Diabetes\" : categorical,\n",
    "              \"Hypertension\" : categorical,\n",
    "              \"Cholesterol Level\" : categorical,\n",
    "              \"Family History of Alzheimer’s\" : categorical,\n",
    "              \"Cognitive Test Score\" : numerical,\n",
    "              \"Depression Level\" : categorical,\n",
    "              \"Sleep Quality\" : categorical,\n",
    "              \"Dietary Habits\" : categorical,\n",
    "              \"Air Pollution Exposure\" : categorical,\n",
    "              \"Employment Status\" : categorical,\n",
    "              \"Marital Status\" : categorical,\n",
    "              \"Genetic Risk Factor (APOE-ε4 allele)\" : categorical,\n",
    "              \"Social Engagement Level\" : categorical,\n",
    "              \"Income Level\" : categorical,\n",
    "              \"Stress Levels\" : categorical,\n",
    "              \"Urban vs Rural Living\" : categorical,\n",
    "              \"Alzheimer’s Diagnosis\" : categorical\n",
    "              }\n",
    "\n",
    "dataset = Dataset(df = df, \n",
    "                  col_to_stype = col_to_stype, \n",
    "                  target_col = \"Alzheimer’s Diagnosis\")\n",
    "\n",
    "dataset.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드로 하니까 되네??? <br>\n",
    "DataFrame 형식이 아니라 이제 materialize가 됨. <br>\n",
    "나중에 더 자세히 알아보쟈 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<stype.categorical: 'categorical'>: ['Air Pollution Exposure', 'Alcohol Consumption', 'Cholesterol Level', 'Country', 'Depression Level', 'Diabetes', 'Dietary Habits', 'Employment Status', 'Family History of Alzheimer’s', 'Gender', 'Genetic Risk Factor (APOE-ε4 allele)', 'Hypertension', 'Income Level', 'Marital Status', 'Physical Activity Level', 'Sleep Quality', 'Smoking Status', 'Social Engagement Level', 'Stress Levels', 'Urban vs Rural Living'], <stype.numerical: 'numerical'>: ['Age', 'BMI', 'Cognitive Test Score', 'Education Level']}\n"
     ]
    }
   ],
   "source": [
    "print(train_tensor_frame.col_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Disease Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Chest_Pain           70000 non-null  float64\n",
      " 1   Shortness_of_Breath  70000 non-null  float64\n",
      " 2   Fatigue              70000 non-null  float64\n",
      " 3   Palpitations         70000 non-null  float64\n",
      " 4   Dizziness            70000 non-null  float64\n",
      " 5   Swelling             70000 non-null  float64\n",
      " 6   Pain_Arms_Jaw_Back   70000 non-null  float64\n",
      " 7   Cold_Sweats_Nausea   70000 non-null  float64\n",
      " 8   High_BP              70000 non-null  float64\n",
      " 9   High_Cholesterol     70000 non-null  float64\n",
      " 10  Diabetes             70000 non-null  float64\n",
      " 11  Smoking              70000 non-null  float64\n",
      " 12  Obesity              70000 non-null  float64\n",
      " 13  Sedentary_Lifestyle  70000 non-null  float64\n",
      " 14  Family_History       70000 non-null  float64\n",
      " 15  Chronic_Stress       70000 non-null  float64\n",
      " 16  Gender               70000 non-null  float64\n",
      " 17  Age                  70000 non-null  float64\n",
      " 18  Heart_Risk           70000 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_disease_risk_dataset_earlymed.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Heart_Risk\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Heart_Risk\"] = df[\"Heart_Risk\"].astype(int)\n",
    "df[\"Heart_Risk\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 직접 설정\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Chest_Pain\" : numerical,\n",
    "              \"Shortness_of_Breath\" : numerical,\n",
    "              \"Fatigue\" : numerical,\n",
    "              \"Palpitations\" : numerical,\n",
    "              \"Dizziness\" : numerical,\n",
    "              \"Swelling\" : numerical,\n",
    "              \"Pain_Arms_Jaw_Back\" : numerical,\n",
    "              \"Cold_Sweats_Nausea\" : numerical,\n",
    "              \"High_BP\" : numerical,\n",
    "              \"High_Cholesterol\" : numerical,\n",
    "              \"Diabetes\" : numerical,\n",
    "              \"Smoking\" : numerical,\n",
    "              \"Obesity\" : numerical,\n",
    "              \"Sedentary_Lifestyle\" : numerical,\n",
    "              \"Family_History\" : numerical,\n",
    "              \"Chronic_Stress\" : numerical,\n",
    "              \"Gender\" : numerical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Heart_Risk\" : numerical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='Heart_Risk')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thyroid Cancer Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212691 entries, 0 to 212690\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Patient_ID           212691 non-null  int64  \n",
      " 1   Age                  212691 non-null  int64  \n",
      " 2   Gender               212691 non-null  object \n",
      " 3   Country              212691 non-null  object \n",
      " 4   Ethnicity            212691 non-null  object \n",
      " 5   Family_History       212691 non-null  object \n",
      " 6   Radiation_Exposure   212691 non-null  object \n",
      " 7   Iodine_Deficiency    212691 non-null  object \n",
      " 8   Smoking              212691 non-null  object \n",
      " 9   Obesity              212691 non-null  object \n",
      " 10  Diabetes             212691 non-null  object \n",
      " 11  TSH_Level            212691 non-null  float64\n",
      " 12  T3_Level             212691 non-null  float64\n",
      " 13  T4_Level             212691 non-null  float64\n",
      " 14  Nodule_Size          212691 non-null  float64\n",
      " 15  Thyroid_Cancer_Risk  212691 non-null  object \n",
      " 16  Diagnosis            212691 non-null  object \n",
      "dtypes: float64(4), int64(2), object(11)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"thyroid_cancer_risk_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Diagnosis\"].unique()    # 진단받았는지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 직접 설정\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={#\"Patient_ID\" : numerical,\n",
    "              \"Age\" : numerical,\n",
    "              \"Gender\" : categorical,\n",
    "              \"Country\" : categorical,\n",
    "              \"Ethnicity\" : categorical,\n",
    "              \"Family_History\" : categorical,\n",
    "              \"Radiation_Exposure\" : categorical,\n",
    "              \"Iodine_Deficiency\" : categorical,\n",
    "              \"Smoking\" : categorical,\n",
    "              \"Obesity\" : categorical,\n",
    "              \"Diabetes\" : categorical,\n",
    "              \"TSH_Level\" : numerical,\n",
    "              \"T3_Level\" : numerical,\n",
    "              \"T4_Level\" : numerical,\n",
    "              \"Nodule_Size\" : categorical,\n",
    "              \"Thyroid_Cancer_Risk\" : categorical,\n",
    "              \"Diagnosis\" : categorical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='Diagnosis')\n",
    "\n",
    "dataset.materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast-cancer.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특이점 : 예측 칼럼 제외 모두 수치형 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"diagnosis\"].unique()    # 이걸 예측하는 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 직접 설정\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M : Malignant\n",
    "- B : Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"radius_mean\" : numerical,\n",
    "              \"texture_mean\" : numerical,\n",
    "              \"perimeter_mean\" : numerical,\n",
    "              \"area_mean\" :numerical,\n",
    "              \"smoothness_mean\" : numerical,\n",
    "              \"compactness_mean\" : numerical,\n",
    "              \"concavity_mean\" : numerical,\n",
    "              \"concave points_mean\" : numerical,\n",
    "              \"symmetry_mean\" : numerical,\n",
    "              \"fractal_dimension_mean\" : numerical,\n",
    "              \"radius_se\" : numerical,\n",
    "              \"texture_se\" : numerical,\n",
    "              \"perimeter_se\" : numerical,\n",
    "              \"area_se\" : numerical,\n",
    "              \"smoothness_se\" : numerical,\n",
    "              \"compactness_se\" : numerical,\n",
    "              \"concavity_se\" : numerical,\n",
    "              \"concave points_se\" : numerical,\n",
    "              \"symmetry_se\" : numerical,\n",
    "              \"fractal_dimension_se\" : numerical,\n",
    "              \"radius_worst\" : numerical,\n",
    "              \"texture_worst\" : numerical,\n",
    "              \"perimeter_worst\" : numerical,\n",
    "              \"area_worst\" : numerical,\n",
    "              \"smoothness_worst\" : numerical,\n",
    "              \"compactness_worst\" : numerical,\n",
    "              \"concavity_worst\" : numerical,\n",
    "              \"concave points_worst\" : numerical,\n",
    "              \"symmetry_worst\" : numerical,\n",
    "              \"fractal_dimension_worst\" : numerical,\n",
    "              \"diagnosis\" : categorical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='diagnosis')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류 task\n",
    "is_classification = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HeartDisease\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 직접 설정\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import numerical, categorical, text_embedded, embedding\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "\n",
    "## 칼럼 별 Dtype 지정 \n",
    "col_to_stype={\"Age\" : numerical,\n",
    "              \"Sex\" : categorical,\n",
    "              \"ChestPainType\" : categorical,\n",
    "              \"RestingBP\" : numerical,\n",
    "              \"Cholesterol\" : numerical,\n",
    "              \"FastingBS\" : numerical,\n",
    "              \"RestingECG\" : categorical,\n",
    "              \"MaxHR\" : numerical,\n",
    "              \"ExerciseAngina\" : categorical,\n",
    "              \"Oldpeak\" : numerical,\n",
    "              \"ST_Slope\" : categorical,\n",
    "              \"HeartDisease\" : numerical}\n",
    "\n",
    "dataset = Dataset(df=df, \n",
    "                  col_to_stype=col_to_stype, \n",
    "                  target_col='HeartDisease')\n",
    "\n",
    "dataset.materialize()\n",
    "\n",
    "## split\n",
    "train_dataset, val_dataset, test_dataset = dataset[:0.6], dataset[0.6:0.7], dataset[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model and optimizer\n",
    "model = TabNet(\n",
    "    out_channels,\n",
    "    num_layers=args.num_layers,\n",
    "    split_attn_channels=args.channels,\n",
    "    split_feat_channels=args.channels,\n",
    "    gamma=args.gamma,\n",
    "    col_stats=dataset.col_stats,\n",
    "    col_names_dict=train_tensor_frame.col_names_dict,\n",
    ").to(device)\n",
    "model = torch.compile(model, dynamic=True) if args.compile else model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    for tf in tqdm(train_loader, desc=f'Epoch: {epoch}'):\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        loss = F.cross_entropy(pred, tf.y.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_accum += float(loss) * len(tf.y)\n",
    "        total_count += len(tf.y)\n",
    "        optimizer.step()\n",
    "    return loss_accum / total_count\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accum = total_count = 0\n",
    "\n",
    "    for tf in loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        pred_class = pred.argmax(dim=-1)\n",
    "        accum += float((tf.y == pred_class).sum())\n",
    "        total_count += len(tf.y)\n",
    "\n",
    "    return accum / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 2/2 [00:00<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6906, Train Acc: 0.5689, Val Acc: 0.7544, Test Acc: 0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 2/2 [00:00<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6845, Train Acc: 0.6422, Val Acc: 0.8070, Test Acc: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 2/2 [00:00<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6797, Train Acc: 0.7038, Val Acc: 0.8596, Test Acc: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 2/2 [00:00<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6742, Train Acc: 0.7449, Val Acc: 0.9649, Test Acc: 0.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 2/2 [00:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6687, Train Acc: 0.7713, Val Acc: 0.9649, Test Acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 2/2 [00:00<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6639, Train Acc: 0.8065, Val Acc: 0.9649, Test Acc: 0.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 2/2 [00:00<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6590, Train Acc: 0.8299, Val Acc: 0.9825, Test Acc: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 2/2 [00:00<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6535, Train Acc: 0.8475, Val Acc: 0.9825, Test Acc: 0.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 2/2 [00:00<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6477, Train Acc: 0.8592, Val Acc: 0.9825, Test Acc: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 2/2 [00:00<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6433, Train Acc: 0.8710, Val Acc: 0.9825, Test Acc: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 2/2 [00:00<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6382, Train Acc: 0.8798, Val Acc: 0.9825, Test Acc: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 2/2 [00:00<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6328, Train Acc: 0.8856, Val Acc: 0.9825, Test Acc: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13: 100%|██████████| 2/2 [00:00<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6269, Train Acc: 0.8974, Val Acc: 0.9825, Test Acc: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 2/2 [00:00<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6235, Train Acc: 0.9003, Val Acc: 0.9825, Test Acc: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 2/2 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6175, Train Acc: 0.9062, Val Acc: 0.9825, Test Acc: 0.9708\n",
      "Best Val Acc: 0.9825, Best Test Acc: 0.9474\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(f'Best Val Acc: {best_val_acc:.4f}, Best Test Acc: {best_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
